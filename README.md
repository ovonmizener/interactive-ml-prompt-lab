# Interactive ML & Prompting Playground ğŸ§ª

A comprehensive full-stack web application for experimenting with machine learning and prompt engineering in real-time. This playground provides an interactive environment to learn, experiment, and build ML models and LLM prompts with guided tutorials and live code snippets.

## ğŸ¯ Project Goals

- **End-to-End ML/DL Flows**: Complete pipeline from data upload â†’ training â†’ explainability
- **LLM Prompt Engineering**: Interactive prompt templates, API calls, and token-level insights
- **Legal-Tech Module**: Semantic search over contracts and legal documents
- **Guided Learning**: Tutorials with live code snippets and real-time experimentation

## ğŸš€ Features

### ğŸ“Š Data Explorer
- Upload CSV/TXT datasets
- Interactive data visualization and statistics
- Data quality analysis and insights
- Correlation matrices and distributions

### ğŸ¤– Model Training
- Multiple ML algorithms (Linear Regression, Random Forest, SVM, Neural Networks)
- Hyperparameter tuning and cross-validation
- Real-time training curves and metrics
- Model comparison and evaluation

### ğŸ’¬ Prompt Workbench
- Live prompt editor with templates
- LLM API integration (GPT, Claude, etc.)
- Token analysis and visualization
- Prompt variations and history

### âš–ï¸ Legal Search
- Document upload and processing
- Semantic search with embeddings
- FAISS-based similarity search
- Legal document analytics

## ğŸ› ï¸ Tech Stack

### Frontend
- **Streamlit**: Interactive web interface with modular pages
- **Plotly**: Rich data visualizations and charts
- **Pandas**: Data manipulation and analysis

### Backend
- **FastAPI**: High-performance API framework
- **Uvicorn**: ASGI server for FastAPI
- **Pydantic**: Data validation and serialization

### Machine Learning
- **Scikit-learn**: Traditional ML algorithms
- **PyTorch/TensorFlow**: Deep learning capabilities
- **SHAP/Captum**: Model explainability
- **FAISS**: Vector similarity search

### LLM & AI
- **OpenAI API**: GPT models integration
- **LangChain**: LLM orchestration
- **Sentence Transformers**: Text embeddings
- **Tiktoken**: Token counting and analysis

### Deployment
- **Docker**: Containerized deployment
- **Multi-service architecture**: FastAPI + Streamlit

## ğŸ“ Project Structure

```
interactive-ml-prompt-lab/
â”œâ”€â”€ app.py                     # FastAPI entrypoint
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ 1_data_explorer.py      # Data upload and visualization
â”‚   â”œâ”€â”€ 2_model_train.py        # ML model training interface
â”‚   â”œâ”€â”€ 3_prompt_workbench.py   # LLM prompt engineering
â”‚   â”œâ”€â”€ 4_legal_search.py       # Legal document search
â”‚   â””â”€â”€ utils.py                # Shared UI components
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ml_pipeline.py          # ML training and evaluation
â”‚   â”œâ”€â”€ explainability.py       # SHAP and model interpretation
â”‚   â”œâ”€â”€ llm_utils.py            # LLM integration and prompts
â”‚   â””â”€â”€ semantic_search.py      # Document search and embeddings
â”œâ”€â”€ tutorials/                  # Learning materials
â”‚   â”œâ”€â”€ 01_prompting_101.md     # Prompt engineering guide
â”‚   â””â”€â”€ 02_ml_fundamentals.md   # ML concepts tutorial
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â””â”€â”€ test_ml_pipeline.py     # ML pipeline tests
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Container configuration
â””â”€â”€ README.md                   # Project documentation
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker (optional, for containerized deployment)
- OpenAI API key (for LLM features)

### Local Development Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/interactive-ml-prompt-lab.git
   cd interactive-ml-prompt-lab
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   ```bash
   # Create .env file
   echo "OPENAI_API_KEY=your_api_key_here" > .env
   ```

5. **Run the application**
   ```bash
   # Start FastAPI backend
   python app.py
   
   # In another terminal, start Streamlit frontend
   streamlit run frontend/1_data_explorer.py
   ```

### Docker Deployment

1. **Build the Docker image**
   ```bash
   docker build -t ml-prompt-playground .
   ```

2. **Run the container**
   ```bash
   docker run -p 8000:8000 -p 8501:8501 ml-prompt-playground
   ```

3. **Access the application**
   - FastAPI: http://localhost:8000
   - Streamlit: http://localhost:8501
   - API Documentation: http://localhost:8000/docs

## ğŸ“– Usage Guide

### Data Explorer

1. **Upload Data**: Use the file uploader to load CSV or TXT files
2. **Explore Statistics**: View data overview, missing values, and distributions
3. **Visualize Data**: Create histograms, correlation matrices, and charts
4. **Data Quality**: Identify issues and get recommendations

### Model Training

1. **Select Model**: Choose from available algorithms
2. **Configure Parameters**: Set hyperparameters and training options
3. **Feature Selection**: Choose relevant features for training
4. **Train Model**: Start training and monitor progress
5. **Evaluate Results**: View metrics, training curves, and model comparison

### Prompt Workbench

1. **Choose Template**: Select from predefined prompt templates
2. **Customize Variables**: Fill in template parameters
3. **Select LLM**: Choose the language model to use
4. **Generate Response**: Get LLM responses with token analysis
5. **Experiment**: Try different prompts and compare results

### Legal Search

1. **Upload Documents**: Add legal documents (PDF, DOCX, TXT)
2. **Generate Embeddings**: Create vector representations
3. **Search**: Perform semantic search with natural language queries
4. **Analyze Results**: View similarity scores and relevance

## ğŸ§ª Tutorials

### Prompt Engineering 101
Learn the fundamentals of prompt engineering:
- Zero-shot vs. few-shot prompting
- Chain-of-thought reasoning
- Role-based prompting
- Token optimization
- Common patterns and best practices

### Machine Learning Fundamentals
Master core ML concepts:
- Supervised vs. unsupervised learning
- Model evaluation metrics
- Feature engineering
- Hyperparameter tuning
- Overfitting and underfitting

## ğŸ§ª Testing

Run the test suite to ensure everything works correctly:

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=core --cov-report=html
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# LLM Configuration
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key

# Model Configuration
DEFAULT_MODEL=gpt-3.5-turbo
MAX_TOKENS=1000
TEMPERATURE=0.7

# Database Configuration
DATABASE_URL=sqlite:///./ml_playground.db

# Security
SECRET_KEY=your_secret_key
```

### API Configuration

The FastAPI backend provides RESTful endpoints:

- `GET /api/health` - Health check
- `POST /api/upload-data` - Upload datasets
- `POST /api/train-model` - Train ML models
- `POST /api/generate-llm` - Generate LLM responses
- `POST /api/semantic-search` - Perform semantic search

## ğŸš€ Future Enhancements

### Planned Features

- **Advanced ML Models**: Deep learning with PyTorch/TensorFlow
- **AutoML**: Automated model selection and hyperparameter tuning
- **Model Deployment**: Export and deploy trained models
- **Collaborative Features**: Share prompts and models
- **Real-time Collaboration**: Multi-user editing
- **Advanced Visualizations**: Interactive dashboards
- **API Integrations**: More LLM providers and services

### Technical Improvements

- **Performance**: Caching and optimization
- **Scalability**: Microservices architecture
- **Security**: Authentication and authorization
- **Monitoring**: Logging and metrics
- **CI/CD**: Automated testing and deployment

### Educational Content

- **Interactive Courses**: Step-by-step learning paths
- **Challenge Mode**: Gamified learning experiences
- **Community Features**: User-generated content
- **Certification**: Learning progress tracking

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

### Code Style

- Follow PEP 8 for Python code
- Use type hints
- Write docstrings for functions
- Add comments for complex logic

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Streamlit](https://streamlit.io/) for the amazing web framework
- [FastAPI](https://fastapi.tiangolo.com/) for the high-performance API
- [OpenAI](https://openai.com/) for LLM capabilities
- [Hugging Face](https://huggingface.co/) for transformers and models
- [Scikit-learn](https://scikit-learn.org/) for machine learning tools

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/interactive-ml-prompt-lab/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/interactive-ml-prompt-lab/discussions)
- **Email**: support@mlplayground.com

## ğŸ“Š Project Status

- âœ… Core ML pipeline
- âœ… Basic prompt engineering
- âœ… Data visualization
- âœ… Legal search module
- ğŸ”„ Advanced ML models
- ğŸ”„ AutoML features
- ğŸ”„ Model deployment
- ğŸ”„ Collaborative features

---

**Happy experimenting! ğŸ‰**

*Built with â¤ï¸ for the ML and AI community*
